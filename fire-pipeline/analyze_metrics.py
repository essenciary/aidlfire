#!/usr/bin/env python3
"""
Analyze training metrics for fire detection / segmentation.

Reads metrics.csv generated by MetricLogger and produces
publication-ready plots.
"""

from pathlib import Path
import argparse

import pandas as pd
import matplotlib.pyplot as plt


def plot_metric(
    df: pd.DataFrame,
    metric: str,
    title: str,
    ylabel: str,
    output_dir: Path,
):
    """Generic metric vs epoch plot."""
    plt.figure(figsize=(7, 4))
    plt.plot(df["epoch"], df[metric], marker="o")
    plt.xlabel("Epoch")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.grid(True)
    plt.tight_layout()

    output_path = output_dir / f"{metric}.png"
    plt.savefig(output_path, dpi=150)
    plt.close()

    print(f"Saved: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="Analyze fire detection training metrics"
    )
    parser.add_argument(
        "--metrics",
        type=Path,
        default=Path("output/metrics.csv"),
        help="Path to metrics.csv",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("output/plots"),
        help="Directory to save plots",
    )
    parser.add_argument(
        "--split",
        type=str,
        default="val",
        choices=["train", "val"],
        help="Which split to analyze",
    )

    args = parser.parse_args()

    args.output_dir.mkdir(parents=True, exist_ok=True)

    # Load metrics
    df = pd.read_csv(args.metrics)

    if args.split not in df["split"].unique():
        raise ValueError(f"Split '{args.split}' not found in metrics.csv")

    df = df[df["split"] == args.split].sort_values("epoch")

    print(f"Loaded {len(df)} epochs for split='{args.split}'")

    # -------------------------
    # SEGMENTATION METRICS
    # -------------------------
    if "fire_iou" in df:
        plot_metric(
            df,
            metric="fire_iou",
            title="Fire IoU (Validation)",
            ylabel="IoU",
            output_dir=args.output_dir,
        )

    if "fire_dice" in df:
        plot_metric(
            df,
            metric="fire_dice",
            title="Fire Dice (Validation)",
            ylabel="Dice",
            output_dir=args.output_dir,
        )

    if "mean_iou" in df:
        plot_metric(
            df,
            metric="mean_iou",
            title="Mean IoU (Validation)",
            ylabel="IoU",
            output_dir=args.output_dir,
        )

    # -------------------------
    # DETECTION METRICS
    # -------------------------
    if "detection_f1" in df:
        plot_metric(
            df,
            metric="detection_f1",
            title="Fire Detection F1 (Validation)",
            ylabel="F1 Score",
            output_dir=args.output_dir,
        )

    if "detection_recall" in df:
        plot_metric(
            df,
            metric="detection_recall",
            title="Fire Detection Recall (Validation)",
            ylabel="Recall",
            output_dir=args.output_dir,
        )

    if "detection_precision" in df:
        plot_metric(
            df,
            metric="detection_precision",
            title="Fire Detection Precision (Validation)",
            ylabel="Precision",
            output_dir=args.output_dir,
        )

    # -------------------------
    # LOSS
    # -------------------------
    if "loss" in df:
        plot_metric(
            df,
            metric="loss",
            title="Loss (Validation)",
            ylabel="Loss",
            output_dir=args.output_dir,
        )

    print("\nAnalysis complete.")
    print(f"Plots saved to: {args.output_dir}")


if __name__ == "__main__":
    main()
